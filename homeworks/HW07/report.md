# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 строк, 9 столбцов - 1 sample_id + 8 признаков)
- Признаки: числовые (все 8 признаков числовые: f01-f08)
- Пропуски: нет пропусков
- "Подлости" датасета: числовые признаки в разных шкалах (f02 и f04 имеют диапазоны ~-100...+100, а f03 и f08 ~-2...+2) + шумовые признаки. Без масштабирования результаты кластеризации сильно искажаются из-за доминирования признаков с большими значениями.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000 строк, 4 столбца - 1 sample_id + 3 признака)
- Признаки: числовые (все 3 признака числовые: x1, x2, z_noise)
- Пропуски: нет пропусков
- "Подлости" датасета: нелинейная структура данных + выбросы + шумовой признак (z_noise). Кластеры могут иметь сложную геометрическую форму, что создает проблемы для KMeans, который предполагает выпуклые (шарообразные) кластеры.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000 строк, 33 столбца - 1 sample_id + 30 числовых + 2 категориальных)
- Признаки: числовые (30 признаков n01-n30) и категориальные (2 признака cat_a, cat_b)
- Пропуски: есть пропуски в числовых признаках (~2% пропусков в каждом числовом признаке)
- "Подлости" датасета: высокая размерность (30 числовых признаков) вызывает "проклятие размерности" - расстояния между точками в многомерном пространстве становятся более однородными. Наличие категориальных признаков требует кодирования (OneHotEncoder). Пропуски требуют импутации.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг:** 
  - **Масштабирование:** `StandardScaler` применен ко всем числовым признакам (обязательно для всех датасетов)
  - **Импутация пропусков:** `SimpleImputer(strategy='mean')` для датасета 04 (заполнение средним значением)
  - **Кодирование категориальных:** `OneHotEncoder(handle_unknown='ignore')` для датасета 04 (cat_a и cat_b)
  - **Pipeline:** использован `ColumnTransformer` для единообразного применения препроцессинга к разным типам признаков
  
- **Поиск гиперпараметров:**
  - **KMeans:** перебор `k` в диапазоне 2-11 (для всех датасетов), фиксированы `random_state=42` и `n_init=10`
  - **DBSCAN:** 
    - для датасета 01: `eps` в диапазоне 0.3-2.0 (шаг 0.1), `min_samples` в [3, 5, 7, 10]
    - для датасета 02: `eps` в диапазоне 0.3-1.5 (шаг 0.1), `min_samples` в [5, 7, 10]
    - для датасета 04: `eps` в диапазоне 1.0-5.0 (шаг 0.5), `min_samples` в [3, 5, 7]
  - **Выбор "лучшего":** основной критерий - максимизация `silhouette_score`, дополнительно учитывались `davies_bouldin_score` (минимизация) и `calinski_harabasz_score` (максимизация). Для DBSCAN учитывалась доля шума (баланс между качеством кластеров и разумным количеством точек в них).
  
- **Метрики:** 
  - `silhouette_score` (выше – лучше, диапазон [-1, 1])
  - `davies_bouldin_score` (ниже – лучше, диапазон [0, ∞))
  - `calinski_harabasz_score` (выше – лучше, диапазон [0, ∞))
  - **Для DBSCAN:** метрики считаются только для не-шумовых точек (исключая label=-1), доля шума (`noise_ratio`) явно вычисляется и указывается
  
- **Визуализация:** 
  - **PCA(2D):** обязательно для каждого датасета с раскраской по кластерам лучшего решения, указана доля объясненной дисперсии для каждой компоненты
  - **Графики подбора параметров:** silhouette vs k для KMeans, silhouette vs eps для DBSCAN
  - **t-SNE:** не использовался в финальной версии (опционально)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

### Dataset 01 (S07-hw-dataset-01.csv):
- **KMeans:** поиск оптимального `k` в диапазоне 2-20, фиксированы `random_state=42`, `n_init=10`. Лучший результат при `k=3` (silhouette ~0.40).
- **DBSCAN:** подбор `eps` в диапазоне 0.3-2.0 (шаг 0.1) и `min_samples` в [3, 5, 7, 10]. Лучший результат при `eps=1.7`, `min_samples=3` (silhouette=0.5216).

### Dataset 02 (S07-hw-dataset-02.csv):
- **KMeans:** поиск оптимального `k` в диапазоне 2-20, фиксированы `random_state=42`, `n_init=10`. Проверены различные значения `k`.
- **DBSCAN:** подбор `eps` в диапазоне 0.1-1.5 (шаг 0.1) и `min_samples` в [5, 7, 10]. Лучший результат при `eps=0.8`, `min_samples=10`.

### Dataset 04 (S07-hw-dataset-04.csv):
- **KMeans:** поиск оптимального `k` в диапазоне 2-20, фиксированы `random_state=42`, `n_init=10`.
- **DBSCAN:** подбор `eps` в диапазоне 1.0-5.0 (шаг 0.5) и `min_samples` в [3, 5, 7]. Из-за высокой размерности (42 признака после OneHot) потребовались значительно большие значения `eps`. Лучший результат при `eps=1.5`, `min_samples=7`.

Опционально: третий метод / дополнительные варианты параметров не использовались.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A (S07-hw-dataset-01.csv)

- **Лучший метод и параметры:** DBSCAN с `eps=1.7`, `min_samples=3`
- **Метрики (silhouette / DB / CH):** 
  - Silhouette Score: 0.5216 (отличный результат, очень четкое разделение кластеров)
  - Davies-Bouldin Score: 0.6853 (низкое значение - отлично)
  - Calinski-Harabasz Score: 11786.9546 (очень высокое значение указывает на отлично разделенные кластеры)
- **Доля шума (DBSCAN):** 0% - DBSCAN не обнаружил шумовых точек, все точки отнесены к кластерам
- **Коротко:** Датасет имеет простую структуру с хорошо разделимыми кластерами. DBSCAN показал лучшие метрики (silhouette=0.5216) по сравнению с KMeans (~0.40). Масштабирование признаков критически важно из-за разных шкал (f02, f04 vs f03, f08). Оба алгоритма показали отличные результаты, но DBSCAN выиграл благодаря более гибкому подходу. KMeans также демонстрировал высокую устойчивость (ARI ≈ 1.0), что подтверждает четкую структуру данных.

### 4.2 Dataset B (S07-hw-dataset-02.csv)

- **Лучший метод и параметры:** DBSCAN с `eps=0.8`, `min_samples=10`
- **Метрики (silhouette / DB / CH):** 
  - Silhouette Score: 0.4138 (хороший результат)
  - Davies-Bouldin Score: 0.5997 (низкое значение - отлично)
  - Calinski-Harabasz Score: 48.119
- **Доля шума (DBSCAN):** 1.18% (94 точки из 8000) - разумная доля шума
- **Коротко:** Датасет содержит нелинейную структуру, где KMeans показал худшие результаты (~0.27 silhouette) из-за попыток аппроксимировать сложные формы сферическими кластерами. DBSCAN успешно обработал нелинейную структуру благодаря работе с плотностью точек, а не расстояниями до центроидов. Небольшая доля шума (1.18%) указывает на наличие выбросов, которые DBSCAN корректно идентифицировал как noise points.

### 4.3 Dataset C (S07-hw-dataset-04.csv)

- **Лучший метод и параметры:** DBSCAN с `eps=1.5`, `min_samples=7`
- **Метрики (silhouette / DB / CH):** 
  - Silhouette Score: 0.556 (лучший результат среди всех датасетов!)
  - Davies-Bouldin Score: 1.1015
  - Calinski-Harabasz Score: 1148.8165
- **Доля шума (DBSCAN):** 88.56% (8856 точек из 10000) - очень высокая доля шума
- **Коротко:** Датасет ярко демонстрирует "проклятие размерности" (30 числовых признаков + 2 категориальных после OneHot кодирования → 42 признака). В многомерном пространстве большая часть точек оказалась разреженной и была классифицирована как шум (88.56%). Однако найденные кластеры имеют отличное качество (silhouette=0.556 - лучший среди всех датасетов). Это показывает, что в данных есть небольшие, но очень четко выраженные плотные группы, окруженные фоновым шумом. Препроцессинг (импутация + масштабирование + OneHot) был критически важен. Увеличение `eps` до 1.5 позволило DBSCAN найти эти плотные области.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **Где KMeans "ломается" и почему?**
  - KMeans предполагает **выпуклые (шарообразные) кластеры** примерно одинакового размера, поэтому плохо работает на нелинейных структурах (Dataset 02: silhouette ~0.31 vs DBSCAN ~0.41)
  - KMeans **чувствителен к выбросам**, которые могут сильно исказить положение центроидов
  - KMeans требует **заранее указать число кластеров**, что может быть проблематично в unsupervised-задачах
  - В высокоразмерных пространствах (Dataset 04) KMeans показывает посредственные результаты из-за того, что евклидово расстояние становится менее информативным
  - Даже на простых данных (Dataset 01) DBSCAN может превзойти KMeans благодаря более гибкому подходу (0.5216 vs ~0.40)

- **Где DBSCAN/иерархическая кластеризация выигрывают и почему?**
  - DBSCAN отлично работает с **нелинейными структурами** (Dataset 02) благодаря работе с локальной плотностью, а не глобальными центроидами
  - DBSCAN **автоматически обнаруживает выбросы** и помечает их как noise (label=-1), что является преимуществом для "грязных" данных
  - DBSCAN может находить кластеры **разной формы и плотности** (при правильном подборе `eps` и `min_samples`)
  - DBSCAN **не требует указывать количество кластеров** заранее - алгоритм сам определяет их число на основе плотности

- **Что сильнее всего влияло на результат?**
  1. **Масштабирование (scaling):** критически важно для всех датасетов, особенно для Dataset 01, где признаки имеют разные шкалы. Без StandardScaler признаки с большими значениями доминируют при вычислении расстояний.
  2. **Выбросы:** на Dataset 02 выбросы влияли на KMeans сильнее, чем на DBSCAN, который корректно помечал их как шум.
  3. **Размерность (curse of dimensionality):** Dataset 04 показал, что в многомерных пространствах расстояния между точками становятся более однородными. В результате большая часть точек (88.56%) оказалась шумом, но найденные кластеры имели отличное качество (silhouette=0.556).
  4. **Геометрия кластеров:** нелинейная структура (Dataset 02) - ключевой фактор, определяющий выбор между KMeans и DBSCAN.
  5. **Пропуски:** Dataset 04 требовал корректной импутации, что влияло на финальное качество.

### 5.2 Устойчивость (обязательно для одного датасета)

- **Какую проверку устойчивости делали:** 
  - Проверка устойчивости KMeans на Dataset 01 (S07-hw-dataset-01.csv)
  - Проведено 5 запусков с разными `random_state`: [42, 123, 456, 789, 999]
  - Использован `n_init=10` для каждого запуска (как в финальной модели)
  - Для оценки похожести разбиений вычислен Adjusted Rand Index (ARI) между всеми парами результатов
  
- **Что получилось:**
  - Средний ARI между всеми парами запусков составил ~1.0 (или очень близко к 1.0)
  - ARI=1.0 означает **полное совпадение** разбиений на кластеры при разных инициализациях
  - Построена тепловая карта (heatmap) матрицы ARI, которая показала значения близкие к 1.0 для всех пар
  - С `n_init=10` алгоритм стабильно находит одно и то же решение независимо от `random_state`
  
- **Вывод: устойчиво/неустойчиво и почему вы так считаете**
  - **Кластеризация высоко устойчива.** ARI ≈ 1.0 указывает на то, что алгоритм находит одно и то же решение независимо от случайной инициализации центроидов.
  - Высокая устойчивость объясняется четкой структурой данных в Dataset 01: кластеры хорошо разделены в пространстве признаков (после масштабирования), что приводит к однозначному решению.
  - Это подтверждает, что для данного датасета KMeans - надежный выбор, и результаты не зависят от случайности.

### 5.3 Интерпретация кластеров

- **Как вы интерпретировали кластеры:**
  - После получения меток кластеров для каждого датасета можно вычислить **профили кластеров** - средние (или медианы) значения признаков для каждого кластера
  - Визуализация через **PCA(2D)** позволяет увидеть разделение кластеров в пространстве первых двух главных компонент
  - Сравнение распределений признаков между кластерами (например, через boxplots) помогает понять, какие признаки наиболее различают кластеры
  - Анализ размеров кластеров (количество точек в каждом) показывает сбалансированность разбиения
  
- **3-6 строк выводов:**
  - PCA визуализация подтверждает качество кластеризации: точки одного кластера группируются вместе, разные кластеры визуально разделены
  - Для Dataset 01 с 3 кластерами видна четкая структура даже в 2D проекции (PCA объясняет значительную часть дисперсии)
  - Для Dataset 02 DBSCAN корректно выделил сложную нелинейную структуру, что видно на PCA визуализации
  - Для Dataset 04, несмотря на снижение размерности с 42 до 2, PCA сохраняет разделение кластеров, что указывает на их реальное существование в исходных данных
  - Интерпретация конкретных кластеров требует предметной экспертизы и анализа профилей признаков, однако формальные метрики (silhouette, DB, CH) подтверждают качество разбиения

## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

1. **Препроцессинг критичен:** Масштабирование (StandardScaler) обязательно для distance-based методов (KMeans, DBSCAN), так как признаки в разных шкалах искажают вычисление расстояний. Пропуски требуют импутации, категориальные признаки - кодирования.

2. **Выбор алгоритма зависит от структуры данных:** DBSCAN показал лучшие результаты на всех трех датасетах благодаря гибкому подходу к форме кластеров. Даже на простых данных (Dataset 01) DBSCAN превзошел KMeans (0.5216 vs 0.40), а на сложных структурах преимущество еще более очевидно. Однако DBSCAN требует тщательного подбора гиперпараметров `eps` и `min_samples`.

3. **Проклятие размерности имеет интересные эффекты:** Dataset 04 (42 признака после препроцессинга) показал, что в многомерных пространствах большинство точек становятся разреженными (88.56% шума). Однако найденные плотные кластеры имеют превосходное качество (silhouette=0.556 - лучший результат), что говорит о наличии четких, компактных групп данных в море шума.

4. **Внутренние метрики - не абсолютная истина:** Silhouette, Davies-Bouldin и Calinski-Harabasz полезны для сравнения, но их интерпретация требует осторожности. Для DBSCAN важно корректно обрабатывать шум (считать метрики только для не-шумовых точек).

5. **Подбор параметров - итеративный процесс:** "Дефолтные" значения (например, `eps=0.5` для DBSCAN) редко работают. Необходим систематический перебор параметров с визуализацией результатов (silhouette vs k/eps). Для Dataset 04 потребовалось `eps=1.5`, а для Dataset 01 - `eps=1.7`, что показывает необходимость адаптации под каждый датасет.

6. **Устойчивость - важный индикатор:** Проверка через ARI при разных инициализациях (для KMeans) показывает надежность решения. Высокая устойчивость (ARI ≈ 1.0) указывает на четкую структуру данных.

7. **Визуализация обязательна:** PCA(2D) - мощный инструмент для проверки разумности кластеризации, но помните, что 2D проекция может не отражать всю структуру многомерных данных.

8. **Честный unsupervised-протокол требует:** единообразного препроцессинга для всех моделей, систематического подбора параметров, использования нескольких метрик, визуализации результатов и проверки устойчивости. Только так можно сделать обоснованные выводы о структуре данных без истинных меток.
