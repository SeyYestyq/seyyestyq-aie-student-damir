# HW06 – Report

> Файл: `homeworks/HW06/report.md`  

## 1. Dataset

- **Выбранный датасет:** `S06-hw-dataset-02.csv`
- **Размер:** (18000 строк, 39 столбцов)
- **Целевая переменная:** `target`. Задача бинарной классификации.
  - Класс 0: 73.7% (13266 примеров)
  - Класс 1: 26.3% (4734 примера)
- **Признаки:**
  - Большинство признаков (`f01`...`f35`) — числовые (float64).
  - Есть синтетические признаки `x_int_1`, `x_int_2`, которые предположительно содержат нелинейные взаимодействия или полиномиальные зависимости.
  - Столбец `id` был удален и не участвовал в обучении.
  - Всего 37 признаков использовалось для обучения (после удаления `id` и `target`).
  - Пропусков в данных нет.

## 2. Protocol

- **Разбиение:** Train (75%) / Test (25%).
  - Train: 13500 примеров (X: 13500×37, y: 13500)
  - Test: 4500 примеров (X: 4500×37, y: 4500)
- **Параметры сплита:** `random_state=42`, `stratify=y` (для сохранения баланса классов).
  - Баланс классов в train: 73.74% класса 0, 26.26% класса 1
  - Баланс классов в test: 73.73% класса 0, 26.27% класса 1
- **Подбор гиперпараметров:**
  - Использовался `GridSearchCV` на Train-выборке.
  - Cross-Validation: 5 фолдов (cv=5).
  - Оптимизируемая метрика: `f1` (так как классификация бинарная и возможен дисбаланс).
- **Метрики оценки (на Test):**
  - `Accuracy`: для общей оценки доли правильных ответов.
  - `F1-score`: как баланс precision и recall, особенно важна при дисбалансе классов.
  - `ROC-AUC`: как основная метрика качества ранжирования (способность модели разделять классы вероятностно), не зависящая от порога.

## 3. Models

Для сравнения были обучены следующие модели:

1. **DummyClassifier (Baseline):** Стратегия `most_frequent`. Служит нижней границей качества (проверка на адекватность).

2. **LogisticRegression (Baseline):** Линейная модель. Использовалась в Pipeline с `StandardScaler`. Служит для сравнения с нелинейными методами.

3. **DecisionTreeClassifier:**
   - Подбирались: `max_depth` (3, 5, 7, 10, None), `min_samples_leaf` (1, 5, 10), `criterion` ('gini', 'entropy').
   - Лучшие параметры: `criterion='gini'`, `max_depth=None`, `min_samples_leaf=10`
   - CV score (F1): 0.6494
   - Цель: найти баланс, чтобы дерево не переобучилось.

4. **RandomForestClassifier:**
   - Подбирались: `n_estimators` (50, 100, 200), `max_depth` (None, 10, 20), `min_samples_leaf` (1, 5), `max_features` ('sqrt', 'log2').
   - Лучшие параметры: `n_estimators=200`, `max_depth=20`, `min_samples_leaf=1`, `max_features='sqrt'`
   - CV score (F1): 0.7521
   - Ансамбль (бэггинг), снижающий разброс (variance).

5. **GradientBoostingClassifier:**
   - Подбирались: `n_estimators` (50, 100, 200), `learning_rate` (0.01, 0.1, 0.2), `max_depth` (3, 5).
   - Лучшие параметры: `n_estimators=200`, `learning_rate=0.2`, `max_depth=5`
   - CV score (F1): 0.7991
   - Ансамбль (бустинг), последовательно исправляющий ошибки предыдущих деревьев.

## 4. Results

Результаты на отложенной тестовой выборке:

| Model | Accuracy | F1 Score | ROC AUC |
| :--- | :--- | :--- | :--- |
| **Dummy Classifier** | 0.7373 | 0.0000 | 0.5000 |
| **Logistic Regression** | 0.8162 | 0.5717 | 0.8009 |
| **Decision Tree** | 0.8342 | 0.6627 | 0.8224 |
| **Random Forest** | 0.8927 | 0.7601 | **0.9286** |
| **Gradient Boosting** | 0.9040 | 0.8009 | 0.9259 |

**Победитель:**
Лучшей моделью оказалась **Random Forest** с ROC-AUC = **0.9286**.
Она превзошла линейный baseline (Logistic Regression с ROC-AUC 0.8009), что подтверждает наличие в данных нелинейных зависимостей, с которыми логистическая регрессия справляется хуже. Random Forest показал наилучшую способность к ранжированию объектов по вероятности принадлежности к классу, хотя Gradient Boosting имеет немного выше F1-score (0.8009 vs 0.7601) и accuracy (0.9040 vs 0.8927).

## 5. Analysis

- **Устойчивость:** Использование `random_state=42` и стратификации позволило получить воспроизводимые результаты. Ансамбли (Лес и Бустинг) показали себя более стабильными методами по сравнению с одиночным деревом, которое склонно менять структуру при малейших изменениях данных. Метрики на тесте сопоставимы с метриками на кросс-валидации, что говорит об отсутствии переобучения:
  - Random Forest: CV F1 = 0.7521, Test F1 = 0.7601 (небольшое улучшение на тесте)
  - Gradient Boosting: CV F1 = 0.7991, Test F1 = 0.8009 (стабильность)
  - Decision Tree: CV F1 = 0.6494, Test F1 = 0.6627 (небольшое улучшение)

- **Ошибки (Confusion Matrix):**
  Судя по матрице ошибок лучшей модели (Random Forest):
  - True Negatives (TN): 3252 (правильно предсказанные классы 0)
  - False Positives (FP): 66 (ложные тревоги — класс 0 предсказан как 1)
  - False Negatives (FN): 417 (пропущенные цели — класс 1 предсказан как 0)
  - True Positives (TP): 765 (правильно предсказанные классы 1)
  
  **Комментарий:** Модель лучше справляется с классом 0 (мажоритарным): из 3318 примеров класса 0 правильно классифицировано 3252 (98.0%). Для класса 1 (миноритарного) ситуация хуже: из 1182 примеров правильно классифицировано 765 (64.7%).  Количество False Negatives (417) значительно превышает False Positives (66), что означает, что модель чаще пропускает положительные примеры, чем создает ложные тревоги.

- **Интерпретация (Permutation Importance):**
  Анализ важности признаков (permutation importance) для лучшей модели (Random Forest) показал топ-10 факторов:
  1. **f16**: 0.0456 ± 0.0030 (наиболее важный признак, значительно превосходит остальные)
  2. **f01**: 0.0195 ± 0.0014
  3. **f19**: 0.0124 ± 0.0012
  4. **f07**: 0.0105 ± 0.0009
  5. **f12**: 0.0094 ± 0.0011
  6. **f30**: 0.0094 ± 0.0005
  7. **f23**: 0.0093 ± 0.0008
  8. **f13**: 0.0079 ± 0.0008
  9. **f18**: 0.0079 ± 0.0011
  10. **f05**: 0.0074 ± 0.0012

  **Вывод:** Наибольший вклад вносят признаки `f16`, `f01`, `f19`, `f07`, `f12`, `f30`. Признак `f16` имеет в 2.3 раза большую важность, чем следующий по важности признак `f01`, что указывает на его критическую роль в предсказании. Интересно, что синтетические признаки `x_int_1` и `x_int_2` не вошли в топ-10, что может означать, что либо они не несут ключевой информации, либо их вклад распределен между другими признаками. Линейная модель (Logistic Regression) не смогла эффективно использовать эти сложные связи между признаками, в то время как ансамбли деревьев (Random Forest и Gradient Boosting) успешно их обнаружили и использовали.

## 6. Conclusion

1. **Сложность данных:** Датасет содержит нелинейности и взаимодействия признаков, поэтому простые линейные модели (Logistic Regression с ROC-AUC 0.8009) проигрывают ансамблям деревьев (Random Forest с ROC-AUC 0.9286, Gradient Boosting с ROC-AUC 0.9259). Улучшение ROC-AUC на ~13% показывает значимость нелинейных зависимостей в данных.

2. **Ансамбли vs Одиночное дерево:** Random Forest и Boosting показали более высокое качество (ROC-AUC 0.9286 и 0.9259 соответственно), чем одиночное Decision Tree (ROC-AUC 0.8224), за счет уменьшения переобучения и дисперсии. Разница в ROC-AUC составляет ~10%, что демонстрирует эффективность ансамблевых методов.

3. **Важность настройки:** GridSearch на кросс-валидации позволил найти параметры, которые не переобучились на train. Метрики на тесте сопоставимы или даже немного лучше, чем на CV, что подтверждает корректность выбранных гиперпараметров.

4. **Честный протокол:** Использование отложенного теста (hold-out) дает объективную оценку: метрики на тесте сопоставимы с метриками на кросс-валидации, что говорит о корректности эксперимента и отсутствии утечки данных.

5. **Дисбаланс классов:** Несмотря на дисбаланс (73.7% vs 26.3%), использование F1-score и ROC-AUC позволило корректно оценить качество моделей. Модели показали хорошую способность к ранжированию (высокий ROC-AUC), хотя и склонны чаще пропускать примеры миноритарного класса (высокое количество False Negatives).

6. **Интерпретируемость:** Permutation importance показал, что признак `f16` является критически важным для предсказания, что может быть полезно для дальнейшего анализа данных и feature engineering.
